//-*-c++-*-
#ifndef LARS__H
#define LARS__H

/** class Lars<DenseLarsData/GeneralLarsData>
 * 
 * Represent the current state of the lars algorithm and can iterate
 * the algorithm.  This does not contain any high-level controls, so
 * the user is encouraged to use the interface functions contained in
 * lars_interface.h.
 *
 * LARS++, Copyright (C) 2007 Varun Ganapathi, David Vickery, James
 * Diebel, Stanford University
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License as
 * published by the Free Software Foundation; either version 2 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
 * 02110-1301 USA.
 */

#include <cstdio>
#include <iostream>
#include <fstream>
#include <iterator>
#include <numeric>
#include <algorithm>
#include <cassert>
#include <cmath>
#include <valarray>

//#include "vec.h"
#include "dense_cholesky.h"

using namespace std;

namespace LARS {
  typedef enum {LAR=-1, LASSO, POSITIVE_LASSO} METHOD;

  template< typename T >
  class Lars {
   public:
    typedef typename T::real real;

    /** get the current parameters */
    const vector<pair<int,real> >& getParameters();

    /** get least squares parameters for active set */
    const void getParameters(vector<pair<int,real> >* p,
			     const vector<pair<int,real> >& b);

    /** performs next iteration of lars */
    bool iterate();

    /** Constructor accepts a LarsDenseData object and a method. */
    Lars( T& data, METHOD m ):
      data_(data), 
      m_(m), 
      small_(numeric_limits<real>::epsilon()),
      chol_( min(data.nrows(),data.ncols())),
      recentDeactivation_(false) 
    { 
      initialize(); 
    }

   private:
    /** initialize the state of LARS */
    void initialize();

    /** add to active set, returns if anything changed */
    bool updateActiveSet();

    /** find search direction */
    void findSearchDirection();

    /** take step along search direction
     *  results in LAR, LASSO, POSITIVE_LASSO */
    void takeStep();

    /** returns true if parameter i is active */
    bool isActive( int i );

    /** activate parameter i and updates cholesky */
    bool activate( int i );

    /** deactivates parameter i and downdates cholesky */
    void deactivate( int i );

    // member variables
    T& data_; // data(contains X and y)
    METHOD m_;            // chooses type of LARS algorithm
    vector<pair<int,real> > beta_;   // current parameters(solution) [Not Sorted]

    // incrementally updated quantities
    valarray<int> active_; // active[i] = position in beta of active param or -1
    vector<real> c_; // correlation of columns of X with current residual
    vector<real> w_;          // step direction ( w_.size() == # active )
    valarray<real> a_;   // correlation of columns of X with current step dir
    real small_;                 // what is small?
    DenseCholesky<real> chol_;   // keeps track of cholesky
    // temporaries
    vector<real> temp_;      // temporary storage for active correlations
    bool recentDeactivation_;  // don't add next step after a deactivation

    bool lassocond;
  };

  /** Initialization routine. */
  template<typename T>
  void Lars<T>::initialize(){
    // initially all parameters are 0
    // so current residual is y
    data_.getXtY( &c_ );
    // step dir = 0 so a_ = 0
    a_.resize(c_.size());
    active_.resize(data_.ncols(),-1);
    temp_.resize(data_.ncols());
  }

  /** Activate all equally corelated x. */
  template<typename T>
  bool Lars<T>::updateActiveSet() {
    if(recentDeactivation_) {
      recentDeactivation_ = false;
      return true;
    }
    bool changed = false;
    // find highest correlation
    real C = 0;
    for(int i=0; i<c_.size(); ++i){
      if( isActive(i) ) continue;
      C = max(fabs(c_[i]), C);
    }

    // activate them if not already active
    for(int i=0; i<c_.size(); ++i) {
      if( !isActive(i) && fabs(fabs(c_[i])-C) < small_ )  {
        if (!activate( i )) return false;
        changed = true;
      }
    }
    return changed;
  }

  /** Returns bool of whether that row is active. */
  template<typename T>
  inline bool Lars<T>::isActive(int i) {
    return active_[i] != -1;
  }

  /** Update state so that feature i is active with weight 0
   *  if it is not already active. */
  template<typename T>
  bool Lars<T>::activate(int i) { 
    if(isActive(i) || beta_.size() >= data_.nrows()) return false;
    active_[i] = beta_.size();
    beta_.push_back(make_pair(i,0.0));
    w_.push_back(0.0);
    // dot i with all the other active columns f => xtx(i,j)
    for(int f=0; f<beta_.size(); ++f){
      temp_[f] = data_.col_dot_product(i, beta_[f].first );
    }
    chol_.addRowCol( &temp_[0] );
    return true;
  }


  /** Update state so that feature i is no longer active if it is
      already active. */
  template<typename T>
  void Lars<T>::deactivate(int i) { 
    //cout << "deactivate(" << i <<")"<< endl;

    if(!isActive(i)) return;
    recentDeactivation_=true;
    int beta_index = active_[i];

    beta_.erase( beta_.begin() + beta_index ); // check this!!
    active_[i] = -1;
    chol_.removeRowCol( beta_index );

    // fix the active set!
    for(int r=0; r<active_.size(); ++r)
      active_[r] = -1;
    for(int r=0; r<beta_.size(); ++r)
      active_[beta_[r].first]=r;
  }

  /** Solves for the step in parameter space given the current
   *  active parameters.
   *  w_ = (X_a'X_a)^(-1) X_a'(residual)
   **/
  template<typename T>
  void Lars<T>::findSearchDirection() {
    for(int i=0; i<beta_.size(); ++i){
      w_[i] = c_[beta_[i].first];
    }

    chol_.solve(w_, &w_ );

    // calculate the a (uses beta to get active indices )
    data_.compute_direction_correlation( beta_, w_, &(a_[0]) );
  }

  /** Take the step! */
  template<typename T>
  void Lars<T>::takeStep() {
    // based on the type, figure out how far we need to go
    // then take the step
    real lambda = 1;
    if(m_ == LAR || m_ == LASSO ) {
      real A = a_[beta_[0].first];
      real C = c_[beta_[0].first];
      for(int j=0; j<a_.size(); ++j) {
        // only consider inactive features
        if(isActive(j)) continue; 

        real t1 = (C - c_[j])/(A - a_[j]);
        real t2 = (C + c_[j])/(A + a_[j]);

        // consider only positive items
        if( t1 > 0 ) lambda = min( lambda, t1 );
        if( t2 > 0 ) lambda = min( lambda, t2 );
      }
    }
    
    int beta_0_index = -1;
    if( m_ == LASSO ) {
      // find out minimum amount so parameter hits 0
      real lambda_0 = numeric_limits<real>::infinity();
      for(int i=0; i<beta_.size(); ++i){
        real temp = -beta_[i].second / w_[i];
        if( temp > 0 && temp < lambda_0 ) {
          lambda_0 = temp;
          beta_0_index = i;
        }
      }

      if( lambda_0 < lambda ) lambda = lambda_0;
      else                    beta_0_index = -1;
    }

    // add lambda * w to beta
    for(int i=0; i<beta_.size(); ++i)
      beta_[i].second += lambda * w_[i];
    // update correlation with a
    for(int i=0; i<c_.size(); ++i)
      c_[i] -= lambda * a_[i];

    if( m_ == LASSO && beta_0_index != -1 ) {
      deactivate( beta_[beta_0_index].first );
    }
  }

  /** Perform a single interation of the LARS loop. */
  template<typename T>
  bool Lars<T>::iterate(){
    if( beta_.size() >= data_.ncols() ) return false;
  
    // we don't update the active set immediately after a deactivation
    if(!updateActiveSet())
      return false; //no new active items
    // disable the flag
    findSearchDirection();
    takeStep();
    return true;
  }

  /** Return a reference to the current active set of beta parameters. */
  template<typename T>
  const vector<pair<int,typename T::real> >& Lars<T>::getParameters() {
    return beta_;
  }

  /** Return the Least-squares solution to X*beta = y for the subset
   * of currently active beta parameters */
  template<typename T>
  const void Lars<T>::
  getParameters(vector<pair<int,typename T::real> >* p, 
		const vector<pair<int,typename T::real> >& b) {

    vector<real> temp(c_.size());
    vector<real> temp2(w_.size());
    
    p->resize(b.size());
    data_.getXtY( &temp );
    for(int i=0; i<b.size(); ++i){
      temp2[i] = temp[b[i].first];
    }
    chol_.solve(temp2, &temp2 );
    for(int i=0; i<b.size(); ++i){
      (*p)[i].first=b[i].first;
      (*p)[i].second=temp2[i];
    }
  }
};
#endif
